{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b312dbe",
   "metadata": {},
   "source": [
    "# Detailed discussion structures\n",
    "\n",
    "This notebook collects more detailed features describing the structure of discussions. The output is a pandas DataFrame containing the following columns:\n",
    "\n",
    "* `review_id` official forum id\n",
    "* `permalink` link to forum on OpenReview\n",
    "* Number of comments\n",
    "  * `total_comments` all comments on forum\n",
    "  * `total_author_comments` all comments from author (continuations counted as separate comments)\n",
    "  * `total_reviewer_comments` total number of comments by all reviewers (continuations are rare)\n",
    "* Number of tokens, as produced by Stanza tokenizer\n",
    "  * `total_tokens` tokens from all comments on forum\n",
    "  * `author_tokens`\n",
    "  * `reviewer_tokens`\n",
    "* `max_path_length` maximum length of a thread in the forum\n",
    "* `max_num_participants` maximum number of unique participants in a thread\n",
    "* `num_unofficial_participants` participants besides authors, reviewers, ACs\n",
    "\n",
    "You can add more features in the `gather_stats` method of `NoteNode`.\n",
    "\n",
    "This code has not been tested with conferences besides ICLR 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27752e03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9a82631bc6143a595c40704aa1a2da5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.0.json:   0%|   â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-29 14:59:32 INFO: Loading these models for language: en (English):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | combined |\n",
      "========================\n",
      "\n",
      "2023-01-29 14:59:32 INFO: Use device: cpu\n",
      "2023-01-29 14:59:32 INFO: Loading: tokenize\n",
      "2023-01-29 14:59:32 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import openreview\n",
    "import pandas as pd\n",
    "import pptree\n",
    "import stanza\n",
    "STANZA_PIPELINE = stanza.Pipeline(lang=\"en\",\n",
    "                                  processors=\"tokenize\")\n",
    "import tqdm\n",
    "\n",
    "\n",
    "# A client is required for any OpenReview API actions\n",
    "guest_client = openreview.Client(baseurl='https://api.openreview.net')\n",
    "\n",
    "# Change these values according to your needs\n",
    "INVITATION = 'ICLR.cc/2019/Conference/-/Blind_Submission'\n",
    "LIMIT = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f065b37e",
   "metadata": {},
   "source": [
    "The cell below contains helper functions including a `NoteNode` object which is intended to be a wrapper around the Note object in the OpenReview API. The main code is in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38dd43d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_author_code(signature):\n",
    "  \"\"\"Returns a short code representing author type.\n",
    "  \n",
    "     This code is only tested for ICLR 2019, but small changes should make it work for other years.\n",
    "  \"\"\"\n",
    "  \n",
    "  # The signature field almost always contains a list of length 1, and the item is almost always of\n",
    "  # the format \"ICLR.cc/<year>/Conference/Paper1592/<entity>\"\n",
    "  sig = signature.split(\"/\")[-1] # extracting the 'entity' part of the signature\n",
    "  \n",
    "  if sig == 'Authors':\n",
    "    return \"A\"\n",
    "  elif sig == \"Conference\":\n",
    "    return \"C\"\n",
    "  elif sig == \"(anonymous)\":\n",
    "    return \"N\"\n",
    "  elif \"Area_Chair\" in sig:\n",
    "    return \"AC\" + sig[-1]\n",
    "  elif \"AnonReviewer\" in sig:\n",
    "    return \"R\" + sig[-1]\n",
    "  elif sig.startswith(\"~\"):\n",
    "    return \"S\" # Someone\n",
    "  else:\n",
    "    print(sig)\n",
    "    assert False # Should not get here for ICLR 2019.\n",
    "    \n",
    "  \n",
    "def get_path(node):\n",
    "  \"\"\"Get a list of note ids leading up to this node, root excluded.\n",
    "  \"\"\"\n",
    "  path = []\n",
    "  while node.reply_to is not None:\n",
    "    path.append(node)\n",
    "    node = node.parent\n",
    "  return list(reversed(path))\n",
    "\n",
    "def get_commenter_path(path):\n",
    "  \"\"\"Get a list of commenters using their author codes, accounting for continuations.\n",
    "  \"\"\"\n",
    "  authors = []\n",
    "  for node in path:\n",
    "    if authors and authors[-1] == node.author:\n",
    "      continue\n",
    "    else:\n",
    "      authors.append(node.author) \n",
    "  return [get_author_code(signature) for signature in authors]\n",
    "\n",
    "def mean(l):\n",
    "  assert l\n",
    "  return sum(l)/len(l)\n",
    "    \n",
    "def get_review_discussions(notes):\n",
    "  \"\"\"Assembles a tree from a list of notes, and calculates features of the tree.\n",
    "  \"\"\"\n",
    "  ordered_notes = list(reversed(sorted([(note.tcdate, note, NoteNode(note)) for note in notes])))\n",
    "  note_objs = {note.id: node for _, note, node in ordered_notes}\n",
    "  root_node = None\n",
    "  for _, _, note_node in ordered_notes:\n",
    "    note_node.tokenize()\n",
    "    if note_node.reply_to is None:\n",
    "      root_node = note_node\n",
    "      continue\n",
    "    elif note_node.reply_to in note_objs:\n",
    "      # Attach parent and children\n",
    "      note_objs[note_node.reply_to].children.append(note_node)\n",
    "      note_node.parent = note_objs[note_node.reply_to]\n",
    "      note_node.assembled = True\n",
    "    else: # A deleted node\n",
    "      return None\n",
    "\n",
    "  return root_node.gather_stats()\n",
    "\n",
    "def get_content_from_note(note):\n",
    "  \"\"\"Extracts the main text from a Note.\"\"\"\n",
    "  if 'review' in note.content:\n",
    "    return note.content['review']\n",
    "  elif 'comment' in note.content:\n",
    "    return note.content['comment']\n",
    "  elif 'metareview' in note.content:\n",
    "    return note.content['metareview']\n",
    "  elif 'abstract' in note.content:\n",
    "    return \"\"\n",
    "  else:\n",
    "    assert False # These are all the valid options for ICLR 2019    \n",
    "\n",
    "class NoteNode(object):\n",
    "  def __init__(self, note):\n",
    "    self.note_id = note.id\n",
    "    self.text = get_content_from_note(note)\n",
    "    self.author, = note.signatures\n",
    "    self.author_code = get_author_code(self.author)\n",
    "    self.short_info = f'{self.author_code}___{self.note_id}'\n",
    "    self.forum_permalink = f\"https://openreview.net/forum?id={note.forum}\"\n",
    "    \n",
    "    self.reply_to = note.replyto\n",
    "    self.parent = None\n",
    "    self.children = []\n",
    "    if self.reply_to is None:\n",
    "      self.assembled = True\n",
    "    else:\n",
    "      self.assembled = False\n",
    "    self.tokenized_text = self.tokenize()\n",
    "\n",
    "    \n",
    "  def tokenize(self):\n",
    "    \"\"\"Tokenize this node's text using Stanza.\"\"\"\n",
    "    doc = STANZA_PIPELINE(self.text)\n",
    "    tokenized_text = []\n",
    "    for sentence in doc.sentences:\n",
    "      tokenized_text.append([token.to_dict()[0][\"text\"] for token in sentence.tokens])\n",
    "    return tokenized_text\n",
    "    \n",
    "  def pretty_print(self):\n",
    "    \"\"\"Print subtree rooted at this node using pptree.\"\"\"\n",
    "    pp_root = pptree.Node(self.short_info)\n",
    "    pp_ancestors = {self.note_id:pp_root}\n",
    "    descendants = list(self.children)\n",
    "    while descendants:\n",
    "      descendant = descendants.pop(0)\n",
    "      descendants += descendant.children\n",
    "      pp_descendant = pptree.Node(descendant.short_info, pp_ancestors[descendant.reply_to])\n",
    "      pp_ancestors[descendant.note_id] = pp_descendant\n",
    "       \n",
    "    pptree.print_tree(pp_root)\n",
    "    \n",
    "  def gather_stats(self):\n",
    "    \n",
    "    # Collect some stats on a BFS\n",
    "    bfs_stats = collections.Counter()\n",
    "    queue = [self]\n",
    "    descendant_map = {} # Collecting nodes with no known children\n",
    "    unofficial_participants = set()\n",
    "    while queue:\n",
    "      curr = queue.pop(0)\n",
    "      if not curr.assembled:\n",
    "        assert False # Shouldn't be able to get here if the nodes in the subtree aren't all assembled\n",
    "      \n",
    "      # Finding descendants\n",
    "      descendant_map[curr.note_id] = curr # This node is a potential descendant\n",
    "      if curr.reply_to in descendant_map:\n",
    "        del(descendant_map[curr.reply_to]) # Remove potential descendant if this node is their child.\n",
    "    \n",
    "      # Counting tokens\n",
    "      num_tokens = len(sum(curr.tokenized_text, []))\n",
    "      bfs_stats[\"total_comments\"] += 1\n",
    "      bfs_stats['total_tokens'] += num_tokens\n",
    "      if curr.author_code.startswith('R'):\n",
    "        bfs_stats[\"total_reviewer_comments\"] += 1\n",
    "        bfs_stats['reviewer_tokens'] += num_tokens\n",
    "      elif curr.author_code == 'A':\n",
    "        bfs_stats[\"total_author_comments\"] += 1\n",
    "        bfs_stats['author_tokens'] += num_tokens\n",
    "      elif not \"C\" in curr.author_code: # Janky way to check for AC (area chair) and C (conference)\n",
    "        unofficial_participants.add(curr.author)\n",
    "      queue += curr.children\n",
    "    \n",
    "    stats = {\n",
    "      \"forum_id\": self.note_id,\n",
    "      \"permalink\": self.forum_permalink,\n",
    "      \"num_unofficial_participants\": len(unofficial_participants),\n",
    "    }\n",
    "    \n",
    "    stats.update(bfs_stats)\n",
    "    \n",
    "    # Instead of doing a DFS, collect the path to each node without children, then calculate\n",
    "    # features of this set of paths.\n",
    "    paths = {descendant_id:get_path(node) for descendant_id, node in descendant_map.items()}\n",
    "    stats[\"max_path_length\"] = max([len(i) for i in paths.values()])\n",
    "    stats[\"mean_path_length\"] = mean([len(i) for i in paths.values()])\n",
    "    stats[\"max_num_participants\"] = max([len(set(get_commenter_path(i))) for i in paths.values()])\n",
    "    \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42419fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:53,  5.94s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>forum_id</th>\n",
       "      <th>permalink</th>\n",
       "      <th>num_unofficial_participants</th>\n",
       "      <th>total_comments</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>total_author_comments</th>\n",
       "      <th>author_tokens</th>\n",
       "      <th>total_reviewer_comments</th>\n",
       "      <th>reviewer_tokens</th>\n",
       "      <th>max_path_length</th>\n",
       "      <th>mean_path_length</th>\n",
       "      <th>max_num_participants</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SJf6BhAqK7</td>\n",
       "      <td>https://openreview.net/forum?id=SJf6BhAqK7</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>8380</td>\n",
       "      <td>9</td>\n",
       "      <td>5066</td>\n",
       "      <td>7</td>\n",
       "      <td>3283</td>\n",
       "      <td>5</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rJl0r3R9KX</td>\n",
       "      <td>https://openreview.net/forum?id=rJl0r3R9KX</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>4359</td>\n",
       "      <td>5</td>\n",
       "      <td>2668</td>\n",
       "      <td>4</td>\n",
       "      <td>1571</td>\n",
       "      <td>4</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SylCrnCcFX</td>\n",
       "      <td>https://openreview.net/forum?id=SylCrnCcFX</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>3648</td>\n",
       "      <td>7</td>\n",
       "      <td>2379</td>\n",
       "      <td>3</td>\n",
       "      <td>1061</td>\n",
       "      <td>2</td>\n",
       "      <td>1.555556</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>H1xAH2RqK7</td>\n",
       "      <td>https://openreview.net/forum?id=H1xAH2RqK7</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>5726</td>\n",
       "      <td>7</td>\n",
       "      <td>4404</td>\n",
       "      <td>3</td>\n",
       "      <td>1195</td>\n",
       "      <td>2</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HJeABnCqKQ</td>\n",
       "      <td>https://openreview.net/forum?id=HJeABnCqKQ</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2703</td>\n",
       "      <td>4</td>\n",
       "      <td>937</td>\n",
       "      <td>6</td>\n",
       "      <td>1364</td>\n",
       "      <td>3</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SyVpB2RqFX</td>\n",
       "      <td>https://openreview.net/forum?id=SyVpB2RqFX</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>9551</td>\n",
       "      <td>12</td>\n",
       "      <td>7097</td>\n",
       "      <td>6</td>\n",
       "      <td>2042</td>\n",
       "      <td>6</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HylTBhA5tQ</td>\n",
       "      <td>https://openreview.net/forum?id=HylTBhA5tQ</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>4270</td>\n",
       "      <td>8</td>\n",
       "      <td>2585</td>\n",
       "      <td>5</td>\n",
       "      <td>1654</td>\n",
       "      <td>7</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>B1gTShAct7</td>\n",
       "      <td>https://openreview.net/forum?id=B1gTShAct7</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>5934</td>\n",
       "      <td>5</td>\n",
       "      <td>3746</td>\n",
       "      <td>6</td>\n",
       "      <td>2136</td>\n",
       "      <td>4</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     forum_id                                   permalink  \\\n",
       "5  SJf6BhAqK7  https://openreview.net/forum?id=SJf6BhAqK7   \n",
       "0  rJl0r3R9KX  https://openreview.net/forum?id=rJl0r3R9KX   \n",
       "1  SylCrnCcFX  https://openreview.net/forum?id=SylCrnCcFX   \n",
       "2  H1xAH2RqK7  https://openreview.net/forum?id=H1xAH2RqK7   \n",
       "3  HJeABnCqKQ  https://openreview.net/forum?id=HJeABnCqKQ   \n",
       "4  SyVpB2RqFX  https://openreview.net/forum?id=SyVpB2RqFX   \n",
       "6  HylTBhA5tQ  https://openreview.net/forum?id=HylTBhA5tQ   \n",
       "7  B1gTShAct7  https://openreview.net/forum?id=B1gTShAct7   \n",
       "\n",
       "   num_unofficial_participants  total_comments  total_tokens  \\\n",
       "5                            0              18          8380   \n",
       "0                            0              11          4359   \n",
       "1                            1              15          3648   \n",
       "2                            1              13          5726   \n",
       "3                            0              12          2703   \n",
       "4                            0              22          9551   \n",
       "6                            0              15          4270   \n",
       "7                            0              13          5934   \n",
       "\n",
       "   total_author_comments  author_tokens  total_reviewer_comments  \\\n",
       "5                      9           5066                        7   \n",
       "0                      5           2668                        4   \n",
       "1                      7           2379                        3   \n",
       "2                      7           4404                        3   \n",
       "3                      4            937                        6   \n",
       "4                     12           7097                        6   \n",
       "6                      8           2585                        5   \n",
       "7                      5           3746                        6   \n",
       "\n",
       "   reviewer_tokens  max_path_length  mean_path_length  max_num_participants  \n",
       "5             3283                5          3.166667                     3  \n",
       "0             1571                4          2.000000                     2  \n",
       "1             1061                2          1.555556                     2  \n",
       "2             1195                2          1.750000                     2  \n",
       "3             1364                3          2.000000                     2  \n",
       "4             2042                6          3.250000                     2  \n",
       "6             1654                7          2.333333                     2  \n",
       "7             2136                4          2.400000                     2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_dicts = []\n",
    "for i, forum_note in tqdm.tqdm(enumerate(openreview.tools.iterget_notes(\n",
    "        guest_client, invitation=INVITATION))):\n",
    "    this_forum_notes = guest_client.get_notes(forum=forum_note.id)\n",
    "    df_dicts.append(get_review_discussions(this_forum_notes))\n",
    "    if i == LIMIT - 1:\n",
    "      break\n",
    "\n",
    "df = pd.DataFrame.from_dict(d for d in df_dicts if d is not None)\n",
    "\n",
    "display(df.sort_values(by='max_num_participants', ascending=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
